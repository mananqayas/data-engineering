# Data engineering

This repo outlines my data engineering learnings. It includes learning hands-on tools used in modern data engineering workflows.

What it includes:

- Used Containerization (Deploy pipeline script as a docker container for repeatability).

- Worked with OLTP databases (Postgres, MySQL).

- Created simple data ingestion pipelines frome external sources and stored them in relational databases using Python scripts and Docker.

- Used Kaggle datasets to explore real-world usecases.

## [Docker](docker)

- Learned how to create custom images, run containers locally and in production.

- Used Python to created pipeline script for batch processing.

- `pandas` and `matplotlib` are used for data manipulation and visualization.

- Used Jupiter Notebook for creating Python scripts.

- Worked with Postgres database using `pgcli`, `psql`, and PgAdmin.
